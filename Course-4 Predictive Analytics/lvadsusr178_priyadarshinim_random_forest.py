# -*- coding: utf-8 -*-
"""LVADSUSR178_PriyadarshiniM_Random_forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XMccQMgNEn0r11iU9DeFCwEYu4c5ZtkG
"""

import numpy as np
import pandas as pd

d=pd.read_csv('/content/winequality-red.csv')

d.head()

d.info()

#1.5 Task
#A. Handle missing values and outliers
d.isnull().sum()

for column in d.select_dtypes(include=['float64']):
  d[column]=d[column].fillna(d[column].mean())

d.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

for column in d.select_dtypes(include=['float64']):
  plt.figure(figsize=(10,5))
  sns.boxplot(d[column])
  plt.title(f'Outliers in {column}')

  plt.show()

#2.Data transformation
d.info()
#In the given dataset, all the values are numerical and therefore, data transformation is not required.

#C.Encoding and balancing data
d.dtypes
d.head()
#In the given dataset, there are no categorical values. So encoding is not needed. Also, the churn
#variable here is taken to be "quality" which shows no imbalance.

#D.Feature Selection and Data cleaning
d.duplicated().sum()

d.shape

d.drop_duplicates(inplace=True)

d.shape

x=d.drop(columns=['quality'])
y=d['quality']

#E.Data splitting
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.3, random_state=10)

#F.Model development
from sklearn.ensemble import RandomForestClassifier

model=RandomForestClassifier(n_estimators=100)
model.fit(x_train, y_train)
pred=model.predict(x_test)
print(pred)

#G. Model Evaluation
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
ac=accuracy_score(pred, y_test)
print(f"Accuracy score is:\n {ac*100}")
# ps=precision_score(pred, y_test)
# print(f"Precision score is:\n {ps}")
# rs=recall_score(pred, y_test)
# print(f"Recall score is:\n {rs}")
cr=classification_report(pred, y_test)
print(f"Classification report is:\n {cr}")